import { useState, useEffect, useRef } from 'react'
import './VoiceInput.css'

interface VoiceInputProps {
  onTranscript: (text: string) => void
  onError?: (error: string) => void
  placeholder?: string
}

export default function VoiceInput({ onTranscript, onError, placeholder = 'ç‚¹å‡»éº¦å…‹é£å¼€å§‹è¯­éŸ³è¾“å…¥' }: VoiceInputProps) {
  const [isListening, setIsListening] = useState(false)
  const [transcript, setTranscript] = useState('')
  const [isSupported, setIsSupported] = useState(true)
  const recognitionRef = useRef<any>(null)

  useEffect(() => {
    // æ£€æŸ¥æµè§ˆå™¨æ˜¯å¦æ”¯æŒWeb Speech API
    const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition

    if (!SpeechRecognition) {
      setIsSupported(false)
      onError?.('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«åŠŸèƒ½')
      return
    }

    // åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«
    const recognition = new SpeechRecognition()
    recognition.lang = 'zh-CN' // è®¾ç½®ä¸ºä¸­æ–‡
    recognition.continuous = false // å•æ¬¡è¯†åˆ«
    recognition.interimResults = true // æ˜¾ç¤ºä¸­é—´ç»“æœ

    recognition.onstart = () => {
      setIsListening(true)
      setTranscript('')
    }

    recognition.onresult = (event: any) => {
      let currentTranscript = ''
      for (let i = event.resultIndex; i < event.results.length; i++) {
        const result = event.results[i]
        if (result.isFinal) {
          currentTranscript += result[0].transcript
        } else {
          currentTranscript += result[0].transcript
        }
      }
      setTranscript(currentTranscript)
    }

    recognition.onend = () => {
      setIsListening(false)
      if (transcript) {
        onTranscript(transcript)
        setTranscript('')
      }
    }

    recognition.onerror = (event: any) => {
      setIsListening(false)
      console.error('è¯­éŸ³è¯†åˆ«é”™è¯¯:', event.error)

      let errorMessage = 'è¯­éŸ³è¯†åˆ«å¤±è´¥'
      switch (event.error) {
        case 'no-speech':
          errorMessage = 'æœªæ£€æµ‹åˆ°è¯­éŸ³ï¼Œè¯·é‡è¯•'
          break
        case 'audio-capture':
          errorMessage = 'æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™'
          break
        case 'not-allowed':
          errorMessage = 'éº¦å…‹é£æƒé™è¢«æ‹’ç»'
          break
        case 'network':
          errorMessage = 'ç½‘ç»œé”™è¯¯ï¼Œè¯·æ£€æŸ¥è¿æ¥'
          break
        default:
          errorMessage = `è¯­éŸ³è¯†åˆ«é”™è¯¯: ${event.error}`
      }
      onError?.(errorMessage)
    }

    recognitionRef.current = recognition

    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.stop()
      }
    }
  }, [transcript])

  const toggleListening = () => {
    if (!isSupported) {
      onError?.('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«åŠŸèƒ½')
      return
    }

    if (isListening) {
      recognitionRef.current?.stop()
    } else {
      recognitionRef.current?.start()
    }
  }

  if (!isSupported) {
    return (
      <div className="voice-input-unsupported">
        <span className="voice-icon">ğŸ¤</span>
        <span className="voice-text">æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¾“å…¥</span>
      </div>
    )
  }

  return (
    <div className="voice-input-container">
      <button
        className={`voice-input-btn ${isListening ? 'listening' : ''}`}
        onClick={toggleListening}
        aria-label={isListening ? 'åœæ­¢å½•éŸ³' : 'å¼€å§‹è¯­éŸ³è¾“å…¥'}
        title={isListening ? 'ç‚¹å‡»åœæ­¢' : placeholder}
      >
        {isListening ? (
          <>
            <span className="voice-icon recording">ğŸ¤</span>
            <span className="voice-wave">
              <span className="wave-bar"></span>
              <span className="wave-bar"></span>
              <span className="wave-bar"></span>
            </span>
          </>
        ) : (
          <span className="voice-icon">ğŸ¤</span>
        )}
      </button>

      {transcript && (
        <div className="voice-transcript">
          <span className="transcript-icon">ğŸ’¬</span>
          <span className="transcript-text">{transcript}</span>
        </div>
      )}
    </div>
  )
}
